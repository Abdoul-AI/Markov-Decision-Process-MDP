{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Algorithmes itératifs pour les processus de décision Markovien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Programmation dynamique à horizon ﬁni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "Vous devez tout d’abord écrire une structure de données d’arbre pondéré comme celui de la\n",
    "ﬁgure ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe représentant notre graphe\n",
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.edges = {} # Seule les arrêtes sont enregistrées\n",
    "        self.value_functions = {} # Stockage des fonctions de valeur\n",
    "    \n",
    "    # Une fonction qui facilite le stockage des arrêtes dans un dictionnaire\n",
    "    def to_string(self,k1, s1, k2, s2):\n",
    "        return str(k1)+','+str(s1)+' -- '+str(k2)+','+str(s2)\n",
    "    \n",
    "    # Stockage du poids de chaque arrête\n",
    "    def add_edge(self,k1, s1, k2, s2, e):\n",
    "        self.edges[self.to_string(k1, s1, k2, s2)] = e\n",
    "        \n",
    "    # Affichage du graph\n",
    "    def print_graph(self):\n",
    "        print('Niceau,Etat -- Niveau,Etat : poid')\n",
    "        for k in self.edges.keys():\n",
    "            print(k,':',self.edges[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niceau,Etat -- Niveau,Etat : poid\n",
      "0,1 -- 1,1 : 1\n",
      "0,1 -- 1,2 : 5\n",
      "0,1 -- 1,3 : -3\n",
      "1,1 -- 2,1 : -2\n",
      "1,1 -- 2,2 : 5\n",
      "1,2 -- 2,1 : 2\n",
      "1,2 -- 2,2 : 7\n",
      "1,2 -- 2,3 : 4\n",
      "1,3 -- 2,2 : 7\n",
      "1,3 -- 2,3 : 3\n",
      "2,1 -- 3,1 : 3\n",
      "2,1 -- 3,2 : 5\n",
      "2,2 -- 3,1 : -2\n",
      "2,2 -- 3,2 : 1\n",
      "2,2 -- 3,3 : 2\n",
      "2,3 -- 3,2 : 0\n",
      "2,3 -- 3,3 : 4\n",
      "3,1 -- 4,1 : 0\n",
      "3,2 -- 4,1 : 0\n",
      "3,3 -- 4,1 : 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = Graph() # Initialisation du graphe\n",
    "\n",
    "# Ajout des différents arrêtes du graph\n",
    "# (Niveau, Etat, Niveau, Etat, poid)\n",
    "g.add_edge(0, 1, 1, 1, 1)\n",
    "g.add_edge(0, 1, 1, 2, 5)\n",
    "g.add_edge(0, 1, 1, 3,-3)\n",
    "g.add_edge(1, 1, 2, 1,-2)\n",
    "g.add_edge(1, 1, 2, 2, 5)\n",
    "g.add_edge(1, 2, 2, 1, 2)\n",
    "g.add_edge(1, 2, 2, 2, 7)\n",
    "g.add_edge(1, 2, 2, 3, 4)\n",
    "g.add_edge(1, 3, 2, 2, 7)\n",
    "g.add_edge(1, 3, 2, 3, 3)\n",
    "g.add_edge(2, 1, 3, 1, 3)\n",
    "g.add_edge(2, 1, 3, 2, 5)\n",
    "g.add_edge(2, 2, 3, 1,-2)\n",
    "g.add_edge(2, 2, 3, 2, 1)\n",
    "g.add_edge(2, 2, 3, 3, 2)\n",
    "g.add_edge(2, 3, 3, 2, 0)\n",
    "g.add_edge(2, 3, 3, 3, 4)\n",
    "g.add_edge(3, 1, 4, 1, 0)\n",
    "g.add_edge(3, 2, 4, 1, 0)\n",
    "g.add_edge(3, 3, 4, 1, 0)\n",
    "\n",
    "# Affichage du graphe de la manière suivante: \"Niveau,Etat -- Niveau,Etat : poid\"\n",
    "g.print_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 \n",
    "Un premier programme déterminera par la méthode de récursivité inverse la fonction de valeur\n",
    "dans chaque état du graphe pour chaque niveau de l’arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de retourner l'ensemble des actions qu'on peut prendre à partir de l'étant courant s et du niveau k\n",
    "def prev_edges(k,s):\n",
    "    edges = list(g.edges.keys()) # Récupération de toutes les arrêtes \n",
    "    items = []\n",
    "    for e in edges:\n",
    "        if '- '+str(k)+','+str(s) in e: # Vérification si l'état courant est la destination dans l'arrête\n",
    "            items.append(e)\n",
    "    return items\n",
    "\n",
    "# Fonction permettant de déterminer par la méthode de récursivité inverse la fonction de valeur dans chaque état du graphe \n",
    "# pour chaque niveau de l’arbre.\n",
    "def V_star(k,s):\n",
    "    if k == 0:\n",
    "        val= 0\n",
    "    else:\n",
    "        val = max([g.edges[e] + V_star(int(e[0]),int(e[2])) for e in prev_edges(k,s)]) # Appel récursif de V_star\n",
    "    g.value_functions['V*(k='+str(k)+',s='+str(s)+')'] = val\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V*(k=0,s=1) = 0\n",
      "V*(k=1,s=1) = 1\n",
      "V*(k=1,s=2) = 5\n",
      "V*(k=2,s=1) = 7\n",
      "V*(k=1,s=3) = -3\n",
      "V*(k=2,s=2) = 12\n",
      "V*(k=3,s=1) = 10\n",
      "V*(k=2,s=3) = 9\n",
      "V*(k=3,s=2) = 13\n",
      "V*(k=3,s=3) = 14\n",
      "V*(k=4,s=1) = 14\n"
     ]
    }
   ],
   "source": [
    "# Calcul des différente fonction de valeur à partir de k = 4, s= 1\n",
    "V_star(4,1)\n",
    "for k in g.value_functions.keys():\n",
    "    print(k,'=',g.value_functions[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Un second programme calculera la politique optimale et donc le chemine le plus long depuis la racine (k = 0) jusqu’aux feuilles (k = T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de déterminer la politique optimale\n",
    "\n",
    "def compute_politique_optimale(k,s):\n",
    "    politique = [] # Stockage de la politique optimale\n",
    "    temp1 = g.value_functions['V*(k='+str(k)+',s='+str(s)+')'] # Récupération de la fonction de valeur de la destination k = 4, s= 1\n",
    "    politique.insert(0,'(k=4,s=1)')\n",
    "    node =  ''\n",
    "    \n",
    "    # Tant que nous ne somme pas arrivé à l'état d'origine k = 0, s= 1, \n",
    "    # continuer par déterminer la prochaine action qui possède le maximum comme fonction de valeur\n",
    "    while k != 0:\n",
    "        temp2 = prev_edges(k,s)\n",
    "        temp3 = [g.value_functions['V*(k='+e[0]+',s='+e[2]+')'] for e in temp2]\n",
    "        val = temp3[0]\n",
    "        node = temp2[0]\n",
    "        for index, e in enumerate(temp3[1:], start = 1):\n",
    "            if e > val:\n",
    "                node = temp2[index]\n",
    "                val = e\n",
    "        k = int(node[0])\n",
    "        s = int(node[2])\n",
    "        politique.insert(0,'(k='+str(k)+',s='+str(s)+')')\n",
    "    return politique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(k=0,s=1)\n",
      "    | \n",
      "    | \n",
      "    v\n",
      "(k=1,s=2)\n",
      "    | \n",
      "    | \n",
      "    v\n",
      "(k=2,s=2)\n",
      "    | \n",
      "    | \n",
      "    v\n",
      "(k=3,s=3)\n",
      "    | \n",
      "    | \n",
      "    v\n",
      "(k=4,s=1)\n",
      "Le chemin le plus long est : V*(k=4,s=1) = 14\n"
     ]
    }
   ],
   "source": [
    "# Affichage du résultat jusqu'à k = 4, s = 1\n",
    "result = compute_politique_optimale(4,1)\n",
    "for k in result[:-1]:\n",
    "    print(k)\n",
    "    print('    | \\n    | \\n    v')\n",
    "print(result[len(result)-1])\n",
    "print('Le chemin le plus long est : V*(k=4,s=1) =',g.value_functions['V*(k='+str(4)+',s='+str(1)+')'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Programmation dynamique à horizon inﬁni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 \n",
    "Un premier programme correspond à l’algorithme de programmation dynamique par itération\n",
    "de la valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data initialisation \n",
    "n = 3\n",
    "m = 4\n",
    "gamma = 0.9\n",
    "start = np.array([2,0])\n",
    "directions = {'LEFT':np.array([0,-1]),'UP':np.array([-1,0]),'RIGHT':np.array([0,1]),'DOWN':np.array([1,0])}\n",
    "actions = np.array(['LEFT','RIGHT','UP','DOWN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0. nan  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Board initialisation\n",
    "V_board = np.zeros((n,m))\n",
    "V_board[0,m-1] = 1\n",
    "V_board[1,m-1] = -1\n",
    "V_board[1,1] = math.nan\n",
    "V_board_prev = V_board.copy()\n",
    "forbidden_positions = [(1,1),(0,3),(1,3)]\n",
    "print(V_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a state is a wall\n",
    "def isWall(position):\n",
    "    if position[0] < 0 or position[0] >= n or position[1] < 0 or position[1] >= m or math.isnan(V_board[position[0],position[1]]):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that compute the sum  ∑s′∈S p(s′|s, a)Vn(s′)]\n",
    "def sum_P_V(position, action):\n",
    "    temp = 0\n",
    "    next_position = position + directions[action]\n",
    "    if isWall(next_position):\n",
    "        temp = temp + V_board_prev[position[0],position[1]]*0.8\n",
    "    else:\n",
    "        temp = temp + V_board_prev[next_position[0],next_position[1]]*0.8\n",
    "        \n",
    "    perpendicular_diraction = []\n",
    "    if action == 'LEFT' or action == 'RIGHT':\n",
    "        perpendicular_diraction.append('UP')\n",
    "        perpendicular_diraction.append('DOWN')\n",
    "    else:\n",
    "        perpendicular_diraction.append('LEFT')\n",
    "        perpendicular_diraction.append('RIGHT')\n",
    "            \n",
    "    \n",
    "    for a in perpendicular_diraction:\n",
    "        next_position = position + directions[a]\n",
    "        if isWall(next_position):\n",
    "            temp = temp + V_board_prev[position[0],position[1]]*0.1\n",
    "        else:\n",
    "            temp = temp + V_board_prev[next_position[0],next_position[1]]*0.1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value iteration function\n",
    "# We assume that the reward is 0 for all other states\n",
    "def value_iteration(position):\n",
    "    return  gamma*max([sum_P_V(position,a) for a in actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iteration : 100\n",
      "[[ 0.644  0.744  0.848  1.   ]\n",
      " [ 0.565    nan  0.572 -1.   ]\n",
      " [ 0.489  0.429  0.475  0.277]]\n"
     ]
    }
   ],
   "source": [
    "# #Test of Value Iteration\n",
    "\n",
    "# nbIteration = 100\n",
    "# for i in range(nbIteration):\n",
    "#     for k in range(n):\n",
    "#         for l in range(m):\n",
    "#             if (k,l) not in forbidden_positions:\n",
    "#                 V_board[k,l] = round(value_iteration([k,l]),3)\n",
    "#     V_board_prev = V_board.copy()\n",
    "\n",
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "# print('Number of iteration :', nbIteration)\n",
    "# print(V_board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Un second programme correspond à la détermination de la politique optimale par itération de\n",
    "la politique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy iteration function\n",
    "def policy_iteration(position):\n",
    "    sum_P_V_list = [sum_P_V(position,a) for a in actions]\n",
    "    sum_P_V_max = max(sum_P_V_list)\n",
    "    policy = actions[np.argmax(sum_P_V_list)]\n",
    "    return  gamma*sum_P_V_max, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation of policy board\n",
    "def init_policy_board():\n",
    "    policy_board = []\n",
    "    for k in range(n):\n",
    "        policy_board.append([])\n",
    "        for l in range(m): \n",
    "            policy_board[k].append(\"     \")\n",
    "    policy_board = np.array(policy_board)      \n",
    "    policy_board[0,3] = 'UP'\n",
    "    policy_board[1,3] = 'LEFT'\n",
    "    policy_board_prev = policy_board.copy()\n",
    "    \n",
    "    return policy_board, policy_board_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iteration :  7\n",
      "[['RIGHT' 'RIGHT' 'RIGHT' 'UP']\n",
      " ['UP' '     ' 'UP' 'LEFT']\n",
      " ['UP' 'RIGHT' 'UP' 'LEFT']]\n"
     ]
    }
   ],
   "source": [
    "Test of Policy iteration\n",
    "\n",
    "policy_board, policy_board_prev = init_policy_board()\n",
    "step = 1\n",
    "while True:\n",
    "    for k in range(n):\n",
    "        for l in range(m):\n",
    "            if (k,l) not in forbidden_positions:\n",
    "                result = policy_iteration([k,l])\n",
    "                V_board[k,l] = round(result[0],3)\n",
    "                policy_board[k,l]= result[1]\n",
    "    V_board_prev = V_board.copy()\n",
    "    step += 1\n",
    "    if step != 1 and np.array_equal(policy_board,policy_board_prev):\n",
    "        break\n",
    "    policy_board_prev = policy_board.copy()\n",
    "print('Number of iteration : ',step)\n",
    "print(policy_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
